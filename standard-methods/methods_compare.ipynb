{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import re\n",
    "import numpy\n",
    "\n",
    "DO_CORRELATIONS, DO_PROJECTIONS, DO_REGRESSIONS, DO_CLUSTERS = True, True, True, True\n",
    "\n",
    "if DO_PROJECTIONS:\n",
    "    # from sklearn import manifold\n",
    "    from sklearn import decomposition\n",
    "if DO_REGRESSIONS:\n",
    "    import statsmodels.api as sm\n",
    "if DO_CLUSTERS:\n",
    "    from sklearn import cluster\n",
    "    from sklearn import metrics\n",
    "    import scipy.cluster\n",
    "    from scipy.sparse.linalg import eigsh\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pdb\n",
    "\n",
    "from tools_all import *\n",
    "\n",
    "NBCS = [3,5,7]\n",
    "NBC = max(NBCS)\n",
    "\n",
    "cmD = make_colormap([d[1] for d in TOL_COLORS if d[0] <= NBC], extrapolate=False)\n",
    "cmC = make_colormap([d[1] for d in TOL_COLORS], extrapolate=True)\n",
    "\n",
    "FSIZE = 3\n",
    "\n",
    "FIGS_REP = \"figs/\"\n",
    "FIGS_EXT = \".png\"\n",
    "\n",
    "# FILE_AGG=\"data_focus_agg.csv\"\n",
    "# FILE_BIO=\"data_focus_bio.csv\"\n",
    "FILE_AGG=\"IUCN_EU_nbspc3+_focus_agg.csv\"\n",
    "FILE_BIO=\"IUCN_EU_nbspc3+_focus_bio.csv\"\n",
    "FILE_CLU=\"data_clusters.csv\"\n",
    "\n",
    "groups_bio = [['bioX1:NPP', 'bio15:PSeason', 'bio12:PTotY'],\n",
    "              ['bio13:PWetM', 'bio16:PWetQ', 'bio14:PDryM', 'bio17:PDryQ', 'bio19:PColdQ', 'bio18:PWarmQ'],\n",
    "              ['bio4:TSeason', 'bio7:TRngY', 'bio2:TMeanRngD', 'bio3:TIso', 'bio1:TMeanY'],\n",
    "              ['bio5:TMaxWarmM', 'bio10:TMeanWarmQuarter', 'bio6:TMinColdM', 'bio11:TMeanColdQ', 'bio8:TMeanWetQ', 'bio9:TMeanDryQ']\n",
    "              ]\n",
    "groups_agg = [['MEAN_HYP', 'MEAN_LOP', 'MEAN_OO', 'MEAN_AL', 'MEAN_OL', 'MEAN_SF'],\n",
    "              ['MEAN_HOD', 'MEAN_LOPT', 'MEAN_OT', 'MEAN_CM', 'MEAN_ETH']              \n",
    "              ]\n",
    "\n",
    "ex_agg = ['MEAN_HOD', 'MEAN_LOPT'] #, 'MEAN_OT', 'MEAN_CM']\n",
    "# groups_bio = [['bioX1:NPP', 'bio15:PSeason', 'bio12:PTotY']]\n",
    "# groups_agg = [['MEAN_HYP', 'MEAN_LOP', 'MEAN_OO', 'MEAN_AL', 'MEAN_OL', 'MEAN_SF']]\n",
    "\n",
    "ABC = load_ABC(FILE_AGG, FILE_BIO, FILE_CLU)\n",
    "A, head_agg, map_agg = ABC[0][\"data\"], ABC[0][\"head\"], ABC[0][\"map\"]\n",
    "B, head_bio, map_bio = ABC[1][\"data\"], ABC[1][\"head\"], ABC[1][\"map\"]\n",
    "C, head_clu, map_clu = ABC[2][\"data\"], ABC[2][\"head\"], ABC[2][\"map\"]\n",
    "\n",
    "#### Log precipitations\n",
    "B_log = numpy.vstack([numpy.log10(B[:,i]+1) if re.match(\"bio[0-9]+:P\", hb) else B[:,i] for i, hb in enumerate(head_bio)]).T\n",
    "# org_map_vnames = dict(map_vnames)\n",
    "# for i, hb in enumerate(head_bio):\n",
    "#     if re.match(\"bio[0-9]+:P\", hb):\n",
    "#         map_vnames[hb] = \"\\\\log(%s)\" % org_map_vnames[hb]\n",
    "\n",
    "#### filter variables\n",
    "keep_agg = [vi for vi, v in enumerate(head_agg) if re.match(\"MEAN_\", v)]\n",
    "keep_aggM = [vi for vi, v in enumerate(head_agg) if re.match(\"MEAN_\", v) and v != \"MEAN_HOD\" and v != \"MEAN_LOPT\"]\n",
    "keep_bio = [vi for vi, v in enumerate(head_bio) if re.match(\"bio[0-9]+:\", v)]\n",
    "\n",
    "Akw = withen(A[:, keep_agg])\n",
    "AMkw = withen(A[:, keep_aggM])\n",
    "Bkw = withen(B[:, keep_bio])\n",
    "BLkw = withen(B_log[:, keep_bio])\n",
    "hA = [head_agg[i] for i in keep_agg]\n",
    "hAM = [head_agg[i] for i in keep_aggM]\n",
    "hB = [head_bio[i] for i in keep_bio]\n",
    "\n",
    "# clu_data = BLkw\n",
    "# clu_data = AMkw #Akw\n",
    "clu_data = numpy.hstack([BLkw, AMkw])\n",
    "\n",
    "lng_lat = B[:, [map_bio[\"longitude\"], map_bio[\"latitude\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_plot(oname):\n",
    "    # plt.savefig(FIGS_REP+oname+FIGS_EXT)\n",
    "    plt.show()\n",
    "    # pass\n",
    "def mk_out(fname):\n",
    "    # return open(FIGS_REP+fname, \"w\")\n",
    "    return sys.stdout\n",
    "def close_out(fo):\n",
    "    # fo.close()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "### Dental traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if DO_CORRELATIONS:\n",
    "    Avs = []\n",
    "    Ahs = []\n",
    "    for hs in groups_agg:\n",
    "        Avs.extend([map_agg[ha] for ha in hs])\n",
    "        Ahs.extend(hs)\n",
    "\n",
    "    n, D, vs, hs = (\"Dent\", A, Avs, Ahs)\n",
    "    corrs = numpy.corrcoef(D[:,vs].T)\n",
    "    \n",
    "    nz = len(vs)\n",
    "    fig, axes = plt.subplots(len(vs)-1, nz-1, figsize=(FSIZE*nz, FSIZE*nz), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "    plot_corrs(D, corrs, vs, hs, axes)\n",
    "    mk_plot(\"correlate%s\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CORRELATIONS:\n",
    " \n",
    "    Bvs = []\n",
    "    Bhs = []\n",
    "    for hs in groups_bio:\n",
    "        Bvs.extend([map_bio[hb] for hb in hs])\n",
    "        Bhs.extend(hs)\n",
    "    \n",
    "    n, D, vs, hs = (\"Clim\", B_log, Bvs, Bhs)\n",
    "    corrs = numpy.corrcoef(D[:,vs].T)\n",
    "\n",
    "    nz = len(vs)\n",
    "    fig, axes = plt.subplots(nz-1, nz-1, figsize=(FSIZE*nz, FSIZE*nz), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})\n",
    "    plot_corrs(D, corrs, vs, hs, axes)\n",
    "    mk_plot(\"correlate%s\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################\n",
    "def project_data(X, model, mname, head, dname, axes, di):\n",
    "        U = numpy.eye(X.shape[1], X.shape[1])\n",
    "        if mname == \"PCA\":\n",
    "            model.fit(X)\n",
    "            Xproj = model.transform(X)\n",
    "            Uproj = model.transform(U)\n",
    "        else:\n",
    "            Xproj = model.fit_transform(numpy.vstack([X[::50, :], U]))\n",
    "            Uproj = Xproj[-U.shape[0]:, :]\n",
    "        plot_proj(Xproj, Uproj, head, dname, axes, di)\n",
    "################################\n",
    "if DO_PROJECTIONS:\n",
    "    NCP=2\n",
    "    datas = [(\"Dent\", Akw, hA),\n",
    "         (\"Dent-{HOD, LOPT}\", AMkw, hAM),\n",
    "         (\"Clim\", BLkw, hB),\n",
    "         (\"Dent+Clim\", numpy.hstack([Akw, BLkw]), hA+hB)\n",
    "         ]\n",
    "    models = [(\"PCA\", decomposition.PCA(n_components=NCP))]#,\n",
    "          # (\"PCoA\", manifold.MDS(n_components=NCP, metric=True)),\n",
    "          # (\"MDS\", manifold.MDS(n_components=NCP, metric=False))]\n",
    "\n",
    "    for mi, (mname, model) in enumerate(models):\n",
    "        fig, axes = plt.subplots(2, len(datas), figsize=(FSIZE*len(datas), FSIZE*2))\n",
    "        for di, (dname, X, head) in enumerate(datas):        \n",
    "            project_data(X, model, mname, head, dname, axes, di)\n",
    "            U = numpy.eye(X.shape[1], X.shape[1])        \n",
    "        mk_plot(\"projection%s\" % mname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressions\n",
    "### One variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "def regress_one_groups(gA, gB, A, head_A, map_A, B, head_B, map_B, collect={}, axes=None):\n",
    "    for i, hb in enumerate(gB):\n",
    "        if hb not in collect:\n",
    "            collect[hb] = {}\n",
    "        for j, ha in enumerate(gA):\n",
    "\n",
    "            ai = map_A[ha]\n",
    "            bi = map_B[hb]\n",
    "            \n",
    "            ##################################\n",
    "            # y = A[:,ai]\n",
    "            # X = B[:,[bi]]\n",
    "            # defv = def_vals.get(ha, 0)\n",
    "            # if defv is not None:\n",
    "            #     ### drop rows with agg==0\n",
    "            #     X = X[y!=defv, :]\n",
    "            #     y = y[y!=defv]                \n",
    "            ##################################\n",
    "            X = A[:,[ai]]\n",
    "            y = B[:,bi]\n",
    "                            \n",
    "            Xr = sm.add_constant(X)\n",
    "            # model = sm.OLS(y, Xr)\n",
    "            model = sm.GLS(y, Xr)\n",
    "            results = model.fit()\n",
    "\n",
    "            if axes is not None:\n",
    "                plot_reg_one(X, y, results, ai, head_A, bi, head_B, axes, i, j)\n",
    "            collect[hb][ha] = results \n",
    "    return collect\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    TOPR = 3\n",
    "    collect = {}\n",
    "    gbi, gai = (0, 0)\n",
    "    gB = groups_bio[gbi]\n",
    "    gA = groups_agg[gai]\n",
    "    nx, ny = len(gA), len(gB)\n",
    "    # ny, nx = len(gA), len(gB)\n",
    "    fig, axes = plt.subplots(ny, nx, figsize=(FSIZE*nx, FSIZE*ny), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})        \n",
    "    regress_one_groups(gA, gB, A, head_agg, map_agg, B_log, head_bio, map_bio, collect, axes)\n",
    "    mk_plot(\"regression1VDent%dvClim%d\" % (gai, gbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    gbi, gai = (0, 1)\n",
    "    gB = groups_bio[gbi]\n",
    "    gA = groups_agg[gai]\n",
    "    nx, ny = len(gA), len(gB)\n",
    "    # ny, nx = len(gA), len(gB)\n",
    "    fig, axes = plt.subplots(ny, nx, figsize=(FSIZE*nx, FSIZE*ny), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})        \n",
    "    regress_one_groups(gA, gB, A, head_agg, map_agg, B_log, head_bio, map_bio, collect, axes)\n",
    "    mk_plot(\"regression1VDent%dvClim%d\" % (gai, gbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    gbi, gai = (1, 0)\n",
    "    gB = groups_bio[gbi]\n",
    "    gA = groups_agg[gai]\n",
    "    nx, ny = len(gA), len(gB)\n",
    "    # ny, nx = len(gA), len(gB)\n",
    "    fig, axes = plt.subplots(ny, nx, figsize=(FSIZE*nx, FSIZE*ny), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})        \n",
    "    regress_one_groups(gA, gB, A, head_agg, map_agg, B_log, head_bio, map_bio, collect, axes)\n",
    "    mk_plot(\"regression1VDent%dvClim%d\" % (gai, gbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    gbi, gai = (1, 1)\n",
    "    gB = groups_bio[gbi]\n",
    "    gA = groups_agg[gai]\n",
    "    nx, ny = len(gA), len(gB)\n",
    "    # ny, nx = len(gA), len(gB)\n",
    "    fig, axes = plt.subplots(ny, nx, figsize=(FSIZE*nx, FSIZE*ny), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})        \n",
    "    regress_one_groups(gA, gB, A, head_agg, map_agg, B_log, head_bio, map_bio, collect, axes)\n",
    "    mk_plot(\"regression1VDent%dvClim%d\" % (gai, gbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    gbi, gai = (2, 0)\n",
    "    gB = groups_bio[gbi]\n",
    "    gA = groups_agg[gai]\n",
    "    nx, ny = len(gA), len(gB)\n",
    "    # ny, nx = len(gA), len(gB)\n",
    "    fig, axes = plt.subplots(ny, nx, figsize=(FSIZE*nx, FSIZE*ny), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})        \n",
    "    regress_one_groups(gA, gB, A, head_agg, map_agg, B_log, head_bio, map_bio, collect, axes)\n",
    "    mk_plot(\"regression1VDent%dvClim%d\" % (gai, gbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    gbi, gai = (2, 1)\n",
    "    gB = groups_bio[gbi]\n",
    "    gA = groups_agg[gai]\n",
    "    nx, ny = len(gA), len(gB)\n",
    "    # ny, nx = len(gA), len(gB)\n",
    "    fig, axes = plt.subplots(ny, nx, figsize=(FSIZE*nx, FSIZE*ny), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})        \n",
    "    regress_one_groups(gA, gB, A, head_agg, map_agg, B_log, head_bio, map_bio, collect, axes)\n",
    "    mk_plot(\"regression1VDent%dvClim%d\" % (gai, gbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    gbi, gai = (3, 0)\n",
    "    gB = groups_bio[gbi]\n",
    "    gA = groups_agg[gai]\n",
    "    nx, ny = len(gA), len(gB)\n",
    "    # ny, nx = len(gA), len(gB)\n",
    "    fig, axes = plt.subplots(ny, nx, figsize=(FSIZE*nx, FSIZE*ny), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})        \n",
    "    regress_one_groups(gA, gB, A, head_agg, map_agg, B_log, head_bio, map_bio, collect, axes)\n",
    "    mk_plot(\"regression1VDent%dvClim%d\" % (gai, gbi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    gbi, gai = (3, 1)\n",
    "    gB = groups_bio[gbi]\n",
    "    gA = groups_agg[gai]\n",
    "    nx, ny = len(gA), len(gB)\n",
    "    # ny, nx = len(gA), len(gB)\n",
    "    fig, axes = plt.subplots(ny, nx, figsize=(FSIZE*nx, FSIZE*ny), \n",
    "                             sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0})        \n",
    "    regress_one_groups(gA, gB, A, head_agg, map_agg, B_log, head_bio, map_bio, collect, axes)\n",
    "    mk_plot(\"regression1VDent%dvClim%d\" % (gai, gbi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_REGRESSIONS:\n",
    "    fo = mk_out(\"regressionModels.txt\")\n",
    "    for hb, xps in collect.items():\n",
    "        bi = map_bio[hb]\n",
    "        y = B_log[:, bi]\n",
    "        fo.write(\"\\n# %s\\n##############\\n\" % hb)\n",
    "        \n",
    "        ks = sorted(xps.keys(), key=lambda x: regres_score(xps[x]))\n",
    "        fo.write(\"\\n\".join([\"\\t%s\\t%s\" % (v, regres_log(xps[v], [v], \"\")) for v in ks[:TOPR]])+\"\\n\")\n",
    "        best_score = regres_score(xps[ks[0]])\n",
    "        \n",
    "        new_xps = {}\n",
    "        new_compat = {}\n",
    "        for i, ki in enumerate(ks):\n",
    "            for j, kj in enumerate(ks[:i]):\n",
    "    \n",
    "                pairH = (kj, ki)\n",
    "                pair = (map_agg[kj], map_agg[ki])\n",
    "                X = A[:, pair]            \n",
    "                \n",
    "                Xr = sm.add_constant(X)\n",
    "                # model = sm.OLS(y, Xr)\n",
    "                model = sm.GLS(y, Xr)\n",
    "                results = model.fit()\n",
    "                if regres_score(results) < best_score:\n",
    "                    new_xps[pairH] = results\n",
    "                    for vp in [0,1]:\n",
    "                        if pairH[vp] not in new_compat:\n",
    "                            new_compat[pairH[vp]] = set()\n",
    "                        new_compat[pairH[vp]].add(pairH[1-vp])\n",
    "    \n",
    "        while len(new_xps) > 0:\n",
    "            xps = new_xps\n",
    "            compat = new_compat\n",
    "            new_xps = {}\n",
    "            new_compat = {}\n",
    "            seen = set()\n",
    "            ks = sorted(xps.keys(), key=lambda x: regres_score(xps[x]))\n",
    "            fo.write(\"--------- (%d)\\n\" % len(ks))\n",
    "            fo.write(\"\\n\".join([\"\\t%s\\t%s\" % (\"+\".join(v), regres_log(xps[v], v, \"\")) for v in ks[:TOPR]])+\"\\n\")\n",
    "            best_score = regres_score(xps[ks[0]])\n",
    "            for k in ks:\n",
    "                common = set.intersection(*[compat[kk] for kk in k])\n",
    "                for c in common:\n",
    "    \n",
    "                    vrsH = tuple(sorted([c]+list(k)))\n",
    "                    if vrsH not in seen:\n",
    "                        seen.add(vrsH)\n",
    "                        \n",
    "                        vrs = [map_agg[v] for v in vrsH]\n",
    "                        X = A[:, vrs]            \n",
    "    \n",
    "                        Xr = sm.add_constant(X)\n",
    "                        # model = sm.OLS(y, Xr)\n",
    "                        model = sm.GLS(y, Xr)\n",
    "                        results = model.fit()\n",
    "                        if regres_score(results) < best_score:\n",
    "                            new_xps[vrsH] = results\n",
    "                            for vi, vp in enumerate(vrsH):\n",
    "                                if vp not in new_compat:\n",
    "                                    new_compat[vp] = set()\n",
    "                                new_compat[vp].update(vrsH[:vi])\n",
    "                            new_compat[vp].update(vrsH[vi+1:])\n",
    "    close_out(fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctypes = [\"C:ones\", \"C:sizes\", \"C:wdist\"]\n",
    "nkmeans = \"k-means\"\n",
    "linkage_args = [(\"Ward\", {\"method\": \"ward\"}),\n",
    "                (\"Complete\", {\"method\": \"complete\"}),\n",
    "                # (\"Single\", {\"method\": \"single\"}),\n",
    "                # (\"Average\", {\"method\": \"average\"}),\n",
    "                # (\"Centroid\", {\"method\": \"centroid\"}),\n",
    "                (\"Weighted\", {\"method\": \"weighted\"}),\n",
    "                (\"Median\", {\"method\": \"median\"})]\n",
    "\n",
    "collect_clusters = []\n",
    "collect_clusters_names = []\n",
    "linkZs = {} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redescriptions based clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CLUSTERS:\n",
    "    \n",
    "    for mi, ctype in enumerate(ctypes):\n",
    "        for ni, nbc in enumerate(NBCS):\n",
    "            keep_ids = C[:,map_clu[\"%s%d\" % (ctype, nbc)]] > -1\n",
    "            cluster_labels = C[keep_ids, map_clu[\"%s%d\" % (ctype, nbc)]].astype(int)\n",
    "            ccounts = numpy.bincount(cluster_labels)\n",
    "            \n",
    "            collect_clusters.append(C[:, map_clu[\"%s%d\" % (ctype, nbc)]].astype(int))\n",
    "            collect_clusters_names.append((ctype, nbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CLUSTERS:\n",
    "    \n",
    "    meths_args = [(nkmeans, cluster.KMeans, {\"n_clusters\": nbc, \"random_state\": 10}) for nbc in NBCS]\n",
    "                  # (\"AP\", cluster.AffinityPropagation, {\"max_iter\": 50})]\n",
    "    \n",
    "    for mi, (mname, meth, args) in enumerate(meths_args):\n",
    "        cluster_labels = meth(**args).fit_predict(clu_data)\n",
    "        ccounts = numpy.bincount(cluster_labels)[1:]\n",
    "        \n",
    "        collect_clusters.append(cluster_labels)\n",
    "        collect_clusters_names.append((mname, args[\"n_clusters\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CLUSTERS:\n",
    "    \n",
    "    for li, (lname, args) in enumerate(linkage_args):\n",
    "        Z = scipy.cluster.hierarchy.linkage(clu_data, **args)\n",
    "        linkZs[lname] = Z\n",
    "        \n",
    "        for ni, nbc in enumerate(NBCS):\n",
    "            cluster_labels = scipy.cluster.hierarchy.fcluster(Z, nbc, criterion=\"maxclust\")\n",
    "            ccounts = numpy.bincount(cluster_labels)[1:]\n",
    "            \n",
    "            collect_clusters.append(cluster_labels)\n",
    "            collect_clusters_names.append((lname, nbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecoregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CLUSTERS:\n",
    "    fig, axes = plt.subplots(figsize=(1.5*FSIZE, 1.5*FSIZE))\n",
    "    ecoregions_labels = C[:, map_clu[\"ECO_CODE\"]].astype(int)\n",
    "    \n",
    "    axes, bm, bm_args = tools_geomap.prepare_map(map_prefs, map_corners[0]+map_corners[1], axe=axes)\n",
    "    xs,ys = bm(lng_lat[:,0], lng_lat[:,1])\n",
    "    axes.scatter(xs, ys, c=ecoregions_labels, s=5, edgecolors='none', zorder=10, alpha=.7)#, cmap=cmC)\n",
    "    # axes.set_xlabel(\" \".join([\"%d\" % len(ccounts)]+[\"%d\" % i for i in ccounts]))\n",
    "    axes.set_title(f\"Ecoregions\")\n",
    "    mk_plot(\"clustersEcoregions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CLUSTERS:\n",
    "    \n",
    "    nmi_meths = [ci for ci, nc in enumerate(collect_clusters_names) if nc[1] == NBC or nc[0] == nkmeans]\n",
    "    nmi_meth_names = [\"%s %d\" % collect_clusters_names[ci] for ci in nmi_meths]+[\"ecoregions\"]\n",
    "    NMI = numpy.ones((len(nmi_meth_names), len(nmi_meth_names)))\n",
    "    for ii, ci in enumerate(nmi_meths):\n",
    "        for jj in range(ii):\n",
    "            NMI[ii,jj] = metrics.normalized_mutual_info_score(collect_clusters[nmi_meths[ii]], collect_clusters[nmi_meths[jj]])\n",
    "            NMI[jj,ii] = NMI[ii,jj]\n",
    "        NMI[ii,-1] = metrics.normalized_mutual_info_score(collect_clusters[nmi_meths[ii]], ecoregions_labels)\n",
    "        NMI[-1,ii] = NMI[ii,-1]\n",
    "\n",
    "    fig, axes = plt.subplots(1,1, figsize=(2*FSIZE, 2*FSIZE))\n",
    "    plt.imshow(NMI, cmap=cmB, vmin=-1, vmax=1)    \n",
    "    plt.xticks(numpy.arange(len(nmi_meth_names)), nmi_meth_names, rotation=45)\n",
    "    plt.yticks(numpy.arange(len(nmi_meth_names)), nmi_meth_names)\n",
    "    axes.xaxis.set_ticks_position('top')\n",
    "    mk_plot(\"clustersNMI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CLUSTERS:\n",
    "    \n",
    "    clusters_sets = {}\n",
    "    map_same = {}\n",
    "    map_cc_cv = {}\n",
    "    clusterings_info = {}\n",
    "    for ci, cc in enumerate(collect_clusters):\n",
    "        ck = collect_clusters_names[ci]\n",
    "        clusterings_info[ck] = {\"ci\": ci, \n",
    "                                \"silhouette\": metrics.silhouette_score(clu_data, cc)}\n",
    "        vals = set(cc)\n",
    "        map_cc_cv[ck] = sorted(vals)\n",
    "        for v in vals:\n",
    "            ss = set(numpy.where(cc==v)[0])\n",
    "            for okv, os in clusters_sets.items():\n",
    "                if okv[0] != ck and len(ss) == len(os) and ss == os:\n",
    "                    if okv not in map_same:                        \n",
    "                        map_same[okv] = okv \n",
    "                    map_same[(ck, v)] = okv\n",
    "                    break\n",
    "            if (ck, v) not in map_same:\n",
    "                clusters_sets[(ck, v)] = ss\n",
    "    cks = sorted(clusters_sets.keys(), key=lambda x: len(clusters_sets[x]))\n",
    "    \n",
    "    contain = {}\n",
    "    for ci in range(len(cks)):\n",
    "        contain[cks[ci]] = []\n",
    "        for cj in range(ci):\n",
    "            if clusters_sets[cks[cj]].issubset(clusters_sets[cks[ci]]):\n",
    "                contain[cks[ci]].append((len(clusters_sets[cks[cj]])/len(clusters_sets[cks[ci]]), cks[cj]))\n",
    "\n",
    "    sub_parts = {}\n",
    "    for k, oss in contain.items():\n",
    "        if len(oss) > 1:\n",
    "            subs = {}\n",
    "            for fct, oks in oss:\n",
    "                if oks[0] not in subs:\n",
    "                    subs[oks[0]] = []\n",
    "                subs[oks[0]].append(oks[1])\n",
    "            X = [okk for okk, ss in subs.items() if len(ss) > 1]            \n",
    "            for x in X:\n",
    "                union_set = set().union(*[clusters_sets[(x, kk)] for kk in subs[x]])\n",
    "                if clusters_sets[k] == union_set:\n",
    "                    if k not in sub_parts:\n",
    "                        sub_parts[k] = []\n",
    "                    sub_parts[k].append([(x, kk) for kk in subs[x]])\n",
    "            if k in sub_parts:\n",
    "                if len(sub_parts[k]) > 1:\n",
    "                    print(\"Multiple mappings\", k, sub_parts[k])\n",
    "                    # pdb.set_trace()\n",
    "                sub_parts[k] = sub_parts[k][0]\n",
    "                    \n",
    "    sml_cks = [ck for ck in cks if ck not in sub_parts]\n",
    "    \n",
    "    dists = numpy.zeros((len(sml_cks), len(sml_cks)))\n",
    "    for ci in range(len(sml_cks)):\n",
    "        for cj in range(ci):\n",
    "            dists[ci,cj] = 1-len(clusters_sets[sml_cks[ci]].intersection(clusters_sets[sml_cks[cj]]))/len(clusters_sets[sml_cks[ci]].union(clusters_sets[sml_cks[cj]]))\n",
    "            dists[cj,ci] = dists[ci,cj]\n",
    "\n",
    "    L = numpy.diag(dists.sum(axis=0)) - dists\n",
    "    egval, egvect = eigsh(L, 2)\n",
    "    ord_ks = numpy.argsort(egvect[:,1])#[-5:]\n",
    "\n",
    "    dist_seq = numpy.array([0.]+[dists[ord_ks[i-1],ord_ks[i]] for i in range(1, len(ord_ks))])\n",
    "    # dist_seq = numpy.array([0.]+[1*(dists[ord_ks[i-1],ord_ks[i]]>0) for i in range(1, len(ord_ks))])\n",
    "    scaleOD = numpy.cumsum(dist_seq/numpy.sum(dist_seq))\n",
    "    map_ccolor_scores = dict(zip([sml_cks[oi] for oi in ord_ks], scaleOD))\n",
    "\n",
    "    clusters_info = {}\n",
    "    for nc, cs in map_cc_cv.items():\n",
    "        for ci in cs:\n",
    "            ck = (nc, ci)\n",
    "            cck = map_same.get(ck, ck)\n",
    "            ccolor, parts = -1, []\n",
    "            if cck in map_ccolor_scores:\n",
    "                ccolor = map_ccolor_scores[cck]\n",
    "            elif cck in sub_parts:\n",
    "                parts = list(sub_parts[cck])\n",
    "                pp_in = [pk for pk in parts if map_same.get(pk, pk) in map_ccolor_scores]\n",
    "                pp_out = [pk for pk in parts if map_same.get(pk, pk) not in map_ccolor_scores]\n",
    "                while len(pp_out) > 0:\n",
    "                    pparts = []\n",
    "                    for pk in pp_out:\n",
    "                        pparts.extend(sub_parts[map_same.get(pk, pk)])\n",
    "                            \n",
    "                    pp_in.extend([pk for pk in pparts if map_same.get(pk, pk) in map_ccolor_scores])\n",
    "                    pp_out = [pk for pk in pparts if map_same.get(pk, pk) not in map_ccolor_scores]\n",
    "                collect_ccolor = [(map_ccolor_scores[pk], len(clusters_sets[pk])) for pk in pp_in]\n",
    "                ccolor = sum([cc[0]*cc[1] for cc in collect_ccolor])/sum([cc[1] for cc in collect_ccolor])\n",
    "                parts = pp_in\n",
    "            else:\n",
    "                print(\"%s NOT FOUND!!\" % ck)\n",
    "                \n",
    "            clusters_info[ck] = {\"basis\": cck, \"ccolor\": ccolor, \"parts\": parts,\n",
    "                              \"center\": numpy.mean(lng_lat[list(clusters_sets[cck]), :], axis=0),\n",
    "                              \"size\": len(clusters_sets[cck]),\n",
    "                              \"label\": chr(ord(\"A\")+int(25*ccolor)) + chr(ord(\"a\")+int(25*(25*ccolor)%25)),\n",
    "                              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CLUSTERS:\n",
    "    \n",
    "    method_family = [nkmeans]+ctypes\n",
    "    nb_rows = len(NBCS)\n",
    "    nb_cols = len(method_family)\n",
    "    fig, axes = plt.subplots(nb_rows, nb_cols, figsize=(FSIZE*nb_cols, FSIZE*nb_rows))\n",
    "    for xi, nm in enumerate(method_family):\n",
    "        for yi, nbc in enumerate(NBCS):\n",
    "            clustering_info = {}\n",
    "            plot_clusters(axes, xi, yi, lng_lat, nm, nbc, map_cc_cv[(nm, nbc)], clusters_sets, clusters_info, clusterings_info[(nm, nbc)], cmC)\n",
    "    mk_plot(\"clustersKRMaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_CLUSTERS:\n",
    "    \n",
    "    method_family = [l[0] for l in linkage_args]\n",
    "    nb_rows = len(NBCS)+1\n",
    "    nb_cols = len(method_family)\n",
    "    fig, axes = plt.subplots(nb_rows, nb_cols, figsize=(FSIZE*nb_cols, FSIZE*nb_rows))\n",
    "    for xi, nm in enumerate(method_family):\n",
    "        scipy.cluster.hierarchy.dendrogram(linkZs[nm], p=3, orientation=\"left\", truncate_mode=\"level\", link_color_func=lambda k: \"black\", no_labels=True, ax=axes[-1,xi])\n",
    "        for yi, nbc in enumerate(NBCS):\n",
    "            clustering_info = {}\n",
    "            plot_clusters(axes, xi, yi, lng_lat, nm, nbc, map_cc_cv[(nm, nbc)], clusters_sets, clusters_info, clusterings_info[(nm, nbc)], cmC)\n",
    "    mk_plot(\"clustersHMaps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
